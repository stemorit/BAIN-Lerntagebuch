---
title: "7 Metadaten modellieren und Schnittstellen nutzen Teil 2"
date: 2020-11-20
---
In dieser Lerneinheit geht es um diese Themen:
* OpenRefine 
* nope, heute nur OpenRefine. Wir hatten schliesslich ja au 4 Stunden Hausaufgaben dazu.


Bevor es aber mit OpenRefine losgeht, ist Zeit für einen kleinen Überblick darüber was wir schon gemacht haben. Wir stehen so ungefähr bei 70% vom Schaubild, das uns durch die Lerneinheiten führt. Wir haben Koha, ArchivesSpace und DSpace angeschaut und dort Daten geharvestet. Das waren die Metadatenformate MARC21, EAD und Dublin Core. Mit MarcEdit haben wir versucht die Daten in MARC21 zu konvertiert als Vorbereitung, um dann die Daten in den Suchindex zu spielen. 
Das Schaubild hat sich zu dieser Lerneinheit geändert. Das neu geänderte Schaubild ist unten abgebildet. 


<img alt="Schaubild" src="https://github.com/stemorit/BAIN-Lerntagebuch/blob/master/_posts/img012-Schaubild-OpenRefine.png?raw=true" width="70%"/>


Es wurde ergänzt durch das Discovery-System OpenRefine. Auf diese Lerneinheit mussten wir die [Lehrmaterialien von Library Carpentry zu OpenRefine](https://librarycarpentry.org/lc-open-refine/) durcharbeiten. Heute möchte ich gerne auf das eingehen, was ich in diesem Lehrmaterial gelernt habe. 

## OpenRefine
<img alt="OpenRefine Claim" src="https://github.com/stemorit/BAIN-Lerntagebuch/blob/master/_posts/img013-OpenRefineClaim.png?raw=true" width="30%"/>


Der Claim von OpenRefine *«A free, open source, powerful tool for working with messy data.»* finde ich eigentlich zimlich cool, wahrscheinlich weil mir das Wort messy data gefällt. Es ist frei, open source, powerful und halt ebe für messy data. 

OpenRefine, was ist das überhaupt für ein komischer Name? Open verstehe ich, ist ja open source. Aber was heisst Refine? Vielleicht hilt ein Translator. Es heisst soviel wie "verfeinern", "veredeln" oder was am meisten Sinn ergibt "weiterentwickeln". Ich würde den Namen jetzt so interpretieren, dass es eine open source ist die immer weiterentwickelt wird. 


**Edit:**

Wie Herr Lohmeier im Unterricht gesagt hat, es wird immer weiterentwickelt von unterschiedlichen Programmierenden.


<img alt="OpenRefine Entwicklung" src="https://github.com/stemorit/BAIN-Lerntagebuch/blob/master/_posts/img013-OpenRefine-Entwicklung.png?raw=true" width="80%"/>

Diese Grafik find ich zimlich cool. Herr Lohmeier hat sie uns in [Github](https://github.com/OpenRefine/OpenRefine/graphs/contributors) gezeigt. Man sieht da, wer wann (bzw. in der Grafik nur wann ohne wer) an OpenRefine rumprogrammiert hat. Man sieht bis 2011 war es super interessant. Dann gabts eine Flaute mit kleinen Ausreissern und ab 2017 wurde es wieder interessant bis zum heutigen Tag. Auf der Seite sieht man auch noch welche Personen daran gearbeitet haben und wann sie daran gearbeitet haben. Sehr spannend, habe nicht gewusst, dass man das auf GitHub so anschauen kann. Sozusagen mein AHA-Effekt von der Lektion.

# Installation

Natürlich hat mir die Installation von OpenRefine auf der virtuellen Maschine schon wieder mega Mühe bereitet. Der Blogpost von Regina hat mir sehr geholfen, es doch noch zu schaffen. Ich musste ewig herumklicken bis die Erlösung kam. Aber das Erfolgserlebnis war dann dafür umso grösser als endlich OpenRefine da war. 

# OpenRefine wofür?
OpenRefine ist ein Werkzeug für die Arbeit mit "Messy Data" also unsauberen, unordentlichen Daten. Es funktioniert am besten mit Daten in einem einfachen Tabellenformat. Es kann helfen, Daten in feinere Teile aufzuteilen, lokale Daten mit anderen Datensätzen abzugleichen oder einen Datensatz mit Daten aus anderen Quellen anzureichern. (Quelle ist die [Library Carpentry](https://librarycarpentry.org/lc-open-refine/))

OpenRefine verwendet Zeilen und Spalten zur Anzeige von Daten. Die meisten Optionen zur Arbeit mit Daten in OpenRefine werden über ein Dropdown-Menü am oberen Rand einer Datenspalte aufgerufen. Wenn man eine Option in einer bestimmten Spalte auswählt, wirkt sich das auf alle Zellen in dieser Spalte aus. OpenRefine verfügt über einen Datensatzmodus, der mehrere Zeilen zu einem einzigen Datensatz verknüpft.

In OpenRefine gibt es einerseits die Row_Ansicht und andererseits die Recods-Ansicht. In der Row-Ansicht repräsentiert jede Zeile ein einzelnes Record und in der Records-Ansicht werden zu einem bestimmten Record alle Zeilen zusammen dargestellt. Im Kapitel [Layout of OpenRefine, Rows vs. Records](https://librarycarpentry.org/lc-open-refine/03-working-with-data/index.html) geht es sonst eigentlich hauptsächlich darum, dass es wichtig ist ein Trennzeichen zu wählen, das nie in den Zellenwerten selbst vorkommt. Aus diesem Grund ist das Pipe-Zeichen (|) eine gute Wahl. Ich finde es jetzt weniger cool, weil es kompliziert ist es mit der Tastatur zu machen. Hauptsach es werden keine Kommas, Doppelpunkte oder Semikolons verwendet. Das ist schön und gut, aber ehrlich gesagt, weiss ich gar nicht warum ich da irgendetwas trennen muss. Ich geh einfach mal weiter im Lehrmaterial. 
Oke, es ging um Facetten und Filter im nächsten Kapitel. Nicht so spannend. Ich schreibe wieder weiter, wenn etwas spannendes kommt.

# Clustering
Das könnte noch spannend sein. 

*Clustering ist eine Methode zum Auffinden von Varianten desselben Datenteils innerhalb eines Datensatzes (z. B. verschiedene Schreibweisen eines Namens). Mit Clustering können Sie unterschiedliche Formen derselben Daten durch einen einzigen konsistenten Wert ersetzen.* ...Hmmm also wäre das wie die Wordfunktion in der man ein Wort durch ein anderes ersetzen kann. Also wenn man z.B. merkt, man hat deshalb immer falsch geschrieben (desshalb, passiert mir ständig) und dann sagt man, man tauscht alle desshalb in deshalb um? Glaube ich liege falsch, da wird noch etwas von Algorithmen gesagt. 
*Die Funktion "Cluster" fasst ähnliche, aber inkonsistente Werte in einer bestimmten Spalte zusammen und ermöglicht es Ihnen, diese inkonsistenten Werte zu einem einzigen Wert Ihrer Wahl zusammenzuführen.* ...Hmm okay, klingt nützlich, lassen wir mal so stehen.




## Fazit:

Also ehrlichgesagt, dieses Tutorial war etwas "messy" für mich. Die Motivation war leider auch recht schnell weg. Ich finde es immer recht schwer einen Sinn zu finden dahinter warum ich den Umgang mit solch spezifischen Software lernen muss, obwohl ich sie nachher nicht mehr brauche und wenn ich es doch mal wieder brauche, muss ich es so oder so neu lernen, weil es sicher nicht gerade im nächsten Monat sein wird. Das selbe gillt aber auch für Koha, ArchivesSpace, DSpace usw. So messy wie die Daten für OpenRefine sind, ist leider auch dieser Blogpost geworden. Bitte schnell weiter und nicht mehr über OpenRefine sprechen. Aber hey, cooler Claim. 

PS: Auf die Bonuspunkte für den Zusatzartikel verzichte ich, da ich mich echt nicht mehr damit beschäftigen mag. 

**Edit zum PS:** 
Herr Lohmeier hat in der nächsten Lehreinheit gesagt, dass weiterhin nur 12 Beiträge im Blog vorliegen müssen um den Kurs zu bestehen und der Zusatzartikel ein Bonus ist für sehr gute Leistungen. Super! Dann muss ich doch kein schlechtes Gewissen haben.





